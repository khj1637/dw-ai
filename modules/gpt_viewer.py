import streamlit as st
import openai
import datetime
from modules.gpt_extract_fields import extract_defect_fields  # (ì°¨í›„ í™œìš© ì˜ˆì •)
from modules.save_utils import save_to_sheet

# âœ… GPT ìœ í˜• ë¶„ë¥˜ í•¨ìˆ˜
def classify_input_type(user_input, api_key):
    openai.api_key = api_key

    system_prompt = """
ë‹¹ì‹ ì€ ì§€ì‹ìˆœí™˜ ì‹œìŠ¤í…œì„ ìœ„í•œ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìì—°ì–´ ì…ë ¥ì„ ì•„ë˜ì˜ ì„¸ ê°€ì§€ ìœ í˜• ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ ì£¼ì„¸ìš”:
- í•˜ìì‚¬ë¡€
- VEì‚¬ë¡€
- ì¼ë°˜ ì§ˆë¬¸ (ì €ì¥ ë¶ˆí•„ìš”)

ê·¸ë¦¬ê³  í•´ë‹¹ íŒë‹¨ì— ëŒ€í•œ ê°„ë‹¨í•œ ì´ìœ ë‚˜ ìš”ì•½ë„ í•¨ê»˜ ì£¼ì„¸ìš”.

ğŸ’¬ ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ ì£¼ì„¸ìš”:
{
  "type": "í•˜ìì‚¬ë¡€" ë˜ëŠ” "VEì‚¬ë¡€" ë˜ëŠ” "ì¼ë°˜ ì§ˆë¬¸",
  "message": "ì´ìœ ë‚˜ ê°„ë‹¨ ìš”ì•½"
}
"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input}
            ],
            temperature=0.3
        )
        content = response.choices[0].message["content"]
        result = eval(content.strip())  # âš ï¸ ë°°í¬ìš©ì€ json.loads()ë¡œ ë³´ì•ˆ ê°•í™” ê¶Œì¥
        return result
    except Exception as e:
        return {"type": "ì˜¤ë¥˜", "message": str(e)}

# âœ… ë©”ì¸ ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤
def render_gpt_viewer():
    st.subheader("ğŸ’¬ ì§€ì‹ìˆœí™˜ GPT (ìì—°ì–´ ì±—ë´‡)")

    # âœ… OpenAI API í‚¤ ì„¤ì •
    api_key = st.secrets.get("OPENAI_API_KEY") or st.text_input("OpenAI API Key", type="password")

    # âœ… ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "register_type" not in st.session_state:
        st.session_state.register_type = None

    # âœ… ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # âœ… ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° (ë§¨ ë§ˆì§€ë§‰ì— ìœ„ì¹˜í•´ì•¼ í•˜ë‹¨ ê³ ì •ë¨)
    user_input = st.chat_input("ê¶ê¸ˆí•œ ì ì´ë‚˜ ì‚¬ë¡€ë¥¼ ìì—°ì–´ë¡œ ì…ë ¥í•´ë³´ì„¸ìš”.")
    if user_input and api_key:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        st.session_state.chat_history.append({"role": "user", "content": user_input})

        # GPT ë¶„ë¥˜
        with st.spinner("GPTê°€ ì…ë ¥ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            result = classify_input_type(user_input, api_key)

        # GPT ì‘ë‹µ ì €ì¥
        st.session_state.chat_history.append({
            "role": "assistant",
            "content": f"**[{result['type']}]** {result['message']}"
        })

        # ìœ í˜• ë¶„ë¥˜ ê²°ê³¼ ì €ì¥
        if result["type"] == "í•˜ìì‚¬ë¡€":
            st.session_state.register_type = "defect"
        elif result["type"] == "VEì‚¬ë¡€":
            st.session_state.register_type = "ve"
        else:
            st.session_state.register_type = None

        # í™”ë©´ ê°±ì‹ 
        st.experimental_rerun()

    # âœ… ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
    if st.session_state.register_type == "defect":
        st.info("â¡ï¸ GPTê°€ ì´ ì…ë ¥ì„ **í•˜ìì‚¬ë¡€**ë¡œ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤. í•­ëª© ì¶”ì¶œ ë° ë“±ë¡ ì ˆì°¨ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        # TODO: render_defect_flow() ë“± ì—°ê²° ì˜ˆì •
    elif st.session_state.register_type == "ve":
        st.info("â¡ï¸ GPTê°€ ì´ ì…ë ¥ì„ **VEì‚¬ë¡€**ë¡œ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤. VE ë“±ë¡ ì ˆì°¨ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        # TODO: render_ve_flow() ë“± ì—°ê²° ì˜ˆì •
